---
name: bbot-helper
description: Provide BBOT (Bighuge BLS OSINT Tool) reconnaissance framework guidance for external penetration testing, including workflow recommendations, preset selection, command construction, and output analysis
version: 1.0.0
pentest_type: external
---

# BBOT Reconnaissance Helper

Expert guidance for using BBOT, the recursive OSINT reconnaissance framework designed for external penetration testing, bug bounty hunting, and attack surface management.

## About BBOT

**BBOT (Bighuge BLS OSINT Tool)** is a recursive, event-driven reconnaissance framework that consistently finds 20-50% more subdomains than competitor tools. Unlike traditional phased tools, BBOT uses an event-driven architecture where each discovery immediately feeds back into the scanning engine, creating continuous discovery loops.

**Key Capabilities:**
- 100+ interconnected modules (subdomain enum, port scanning, web tech detection, cloud discovery)
- Multiple output formats (JSON, CSV, Neo4j, asset inventory)
- Recursive discovery (findings trigger new scans automatically)
- Modular and extensible
- Integration-ready (exports to nmap, nuclei, other tools)

## When to Use This Skill

Use this skill when working on external penetration tests and need help with:
- Choosing the right bbot workflow for your engagement phase
- Building bbot commands with appropriate presets and modules
- Understanding bbot module flags and scope management
- Analyzing bbot outputs and identifying high-value targets
- Exporting bbot discoveries to other tools (nmap, nuclei, burp)
- Configuring API keys for maximum coverage
- Troubleshooting bbot scans

## Your Role

As the BBOT specialist, provide:
1. **Workflow Recommendations** - Guide users through passive → active → comprehensive phased approach
2. **Command Construction** - Build proper bbot commands based on engagement objectives
3. **Output Analysis** - Parse bbot JSON/CSV outputs and highlight interesting findings
4. **Integration Guidance** - Show how to export bbot results to other tools
5. **Best Practices** - Scope management, performance optimization, API configuration

---

## Phased Reconnaissance Approach

External pentests should progress through three phases with BBOT:

### Phase 1: Passive Reconnaissance

**Objective:** Map attack surface without touching the target (safe, passive OSINT)

**Command Pattern:**
```bash
bbot -t TARGET.com -f safe -rf passive -om json,csv -o outputs/recon/passive_$(date +%Y%m%d) -n passive_recon
```

**What This Does:**
- `-f safe` - Only run safe modules (no active scanning)
- `-rf passive` - Require modules to be passive (no direct target contact)
- `-om json,csv` - Output JSON and CSV formats for analysis
- `-o` - Custom output directory with timestamp
- `-n` - Named scan for easy reference

**Expected Results:**
- Subdomains from passive sources (certificate transparency, DNS databases, APIs)
- Associated IP addresses
- Email addresses and employee information
- Technology stack information
- Cloud resources (S3 buckets, Azure storage, etc.)

**When to Use:** Day 1 of engagement, before any active scanning authorized

**Next Steps After Passive:**
1. Review discovered subdomains
2. Identify in-scope vs out-of-scope assets
3. Create target lists for active reconnaissance
4. Update scope documentation

---

### Phase 2: Active Reconnaissance

**Objective:** Validate passive findings and actively discover additional assets

**Command Pattern:**
```bash
bbot -t TARGET.com -p subdomain-enum -m portscan httpx gowitness -om json,csv,neo4j -o outputs/discovery/active_$(date +%Y%m%d) -n active_discovery
```

**What This Does:**
- `-p subdomain-enum` - Use subdomain-enum preset (APIs + DNS brute-force)
- `-m portscan httpx gowitness` - Add port scanning, HTTP probing, screenshots
- `-om json,csv,neo4j` - Multiple outputs including Neo4j for visualization

**Additional Modules to Consider:**
- `sslcert` - Extract domains from SSL certificates
- `azure_tenant` - Enumerate Azure tenant information
- `bucket_*` - Search for cloud storage buckets (S3, Azure, GCP)
- `nuclei` - Run nuclei vulnerability scans on discovered web apps

**Expected Results:**
- Comprehensive subdomain list (20-50% more than passive)
- Open ports and services
- Live web applications
- Screenshots of web interfaces
- Cloud resource discoveries
- Potential vulnerabilities (if using nuclei)

**When to Use:** After passive recon complete and active testing authorized

**Scope Management:**
Use whitelists and blacklists to control scanning:
```bash
# Whitelist specific IP range
bbot -t TARGET.com -p subdomain-enum --whitelist 192.0.2.0/24

# Blacklist out-of-scope subdomain
bbot -t TARGET.com -p subdomain-enum --blacklist prod.target.com

# Strict scope (only exact targets, no auto-expansion)
bbot -t TARGET.com --strict-scope -p subdomain-enum
```

---

### Phase 3: Comprehensive Enumeration

**Objective:** "Everything everywhere all at once" - maximum coverage

**Command Pattern:**
```bash
bbot -t TARGET.com -p kitchen-sink --allow-deadly -om json,csv,neo4j,asset_inventory -o outputs/comprehensive/full_$(date +%Y%m%d) -n comprehensive_scan
```

**What This Does:**
- `-p kitchen-sink` - Combines subdomain-enum, cloud-enum, code-enum, email-enum, spider, web-basic, paramminer, dirbust-light, web-screenshots
- `--allow-deadly` - Enable aggressive modules (required for kitchen-sink)
- `-om asset_inventory` - Generate CSV with hosts, cloud providers, IPs, open ports

**Warning:** Kitchen-sink is aggressive and will:
- Generate significant network traffic
- Trigger security alerts
- Take considerable time to complete
- Potentially cause rate limiting

**When to Use:**
- When authorized for aggressive testing
- For thorough attack surface assessment
- When time permits comprehensive enumeration
- For ongoing attack surface management

**Expected Results:**
- Complete attack surface mapping
- Code repositories (GitHub, GitLab)
- Email addresses and employees
- Web application parameters
- Directory/file listings
- Cloud resources across AWS/Azure/GCP
- Detailed asset inventory

---

## Module Flags and Selection

BBOT modules are tagged with flags for easy filtering:

### Safety Flags
- `safe` - Non-disruptive modules (OSINT, passive enum)
- `aggressive` - May trigger alerts (directory bruteforce, heavy scanning)
- `deadly` - Dangerous modules (password spraying, exploitation) - **Use with caution**

### Activity Flags
- `passive` - No direct target contact (API lookups, certificate transparency)
- `active` - Direct target interaction (DNS queries, HTTP requests)

### Functional Flags
- `subdomain-enum` - Subdomain discovery modules
- `cloud-enum` - Cloud resource enumeration (AWS, Azure, GCP)
- `web` - Web application scanning
- `code-enum` - Code repository discovery
- `email-enum` - Email address harvesting
- `portscan` - Port and service scanning
- `brute-force` - Directory/DNS bruteforcing
- `slow` - Modules that take significant time

### Example Flag Combinations

**Passive subdomain enumeration only:**
```bash
bbot -t target.com -f subdomain-enum -rf passive
```

**All safe modules, excluding active ones:**
```bash
bbot -t target.com -f safe -ef active
```

**Subdomain enum + web scanning, no brute-force:**
```bash
bbot -t target.com -f subdomain-enum -f web -ef brute-force
```

**Cloud enumeration only:**
```bash
bbot -t target.com -f cloud-enum
```

---

## Common Presets

BBOT includes built-in presets for common workflows:

### subdomain-enum
Comprehensive subdomain discovery via APIs + brute-force
```bash
bbot -t target.com -p subdomain-enum
```

### web-basic
Light web scanning (wappalyzer, robots.txt, security headers)
```bash
bbot -t target.com -p web-basic
```

### spider
Recursive web crawling with email extraction
```bash
bbot -t target.com -p spider
```

### kitchen-sink
Everything combined (requires --allow-deadly)
```bash
bbot -t target.com -p kitchen-sink --allow-deadly
```

### Custom Preset Combinations
Combine presets for tailored scanning:
```bash
bbot -t target.com -p subdomain-enum -p web-basic -m nuclei
```

---

## Command Builder

### Basic Structure
```bash
bbot -t <TARGETS> [FLAGS] [MODULES] [OUTPUT] [SCOPE]
```

### Interactive Command Construction

**Step 1: Define Targets**
```bash
# Single domain
-t example.com

# Multiple domains
-t example.com,app.example.com

# IP range
-t 192.0.2.0/24

# Mixed targets
-t example.com,192.0.2.0/24
```

**Step 2: Choose Approach**

For passive reconnaissance:
```bash
-f safe -rf passive
```

For active discovery:
```bash
-p subdomain-enum
```

For comprehensive scan:
```bash
-p kitchen-sink --allow-deadly
```

**Step 3: Add Specific Modules**

Enhance with additional modules:
```bash
-m portscan httpx nuclei gowitness
```

**Step 4: Configure Output**

Always use multiple output formats:
```bash
-om json,csv,neo4j -o outputs/discovery -n scan_name
```

**Step 5: Manage Scope**

For strict scope:
```bash
--strict-scope
```

For whitelisting specific ranges:
```bash
--whitelist 192.0.2.0/24
```

For blacklisting out-of-scope items:
```bash
--blacklist internal.example.com
--blacklist "RE:signout"  # regex pattern
```

### Full Example Commands

**Passive Recon (Day 1):**
```bash
bbot -t megacorp.com \
  -f safe -rf passive \
  -om json,csv \
  -o ~/pentests/megacorp/outputs/passive \
  -n passive_$(date +%Y%m%d)
```

**Active Discovery (Day 2-3):**
```bash
bbot -t megacorp.com \
  -p subdomain-enum \
  -m portscan httpx gowitness nuclei \
  --whitelist 198.51.100.0/24 \
  -om json,csv,neo4j \
  -o ~/pentests/megacorp/outputs/active \
  -n active_$(date +%Y%m%d)
```

**Targeted Web Scan:**
```bash
bbot -t app.megacorp.com \
  -p spider -p web-basic \
  -m paramminer \
  --strict-scope \
  -om json,csv \
  -o ~/pentests/megacorp/outputs/web_scan \
  -n web_app_scan
```

---

## Output Analysis

BBOT generates multiple output formats in `~/.bbot/scans/[scan-name]/`:

### Human-Readable Output

**output.txt** - Tab-delimited, grep-optimized
```bash
# Find all discovered subdomains
grep DNS_NAME output.txt

# Find all open ports
grep OPEN_TCP_PORT output.txt

# Find potential vulnerabilities
grep VULNERABILITY output.txt
```

### JSON Output

**output.json** - Newline-delimited JSON events

Parse with jq for analysis:
```bash
# Extract all discovered domains
cat output.json | jq -r 'select(.type=="DNS_NAME") | .data' | sort -u

# Find admin panels
cat output.json | jq -r 'select(.data | contains("admin")) | .data'

# List all cloud resources
cat output.json | jq 'select(.type | contains("STORAGE"))'

# Get all findings with severity
cat output.json | jq 'select(.type=="FINDING") | {finding: .data, severity: .tags}'
```

### CSV Output

**output.csv** - Spreadsheet-friendly format

Columns: Event Type, Event Data, IP Address, Source Module, Scope Distance, Tags

Load into spreadsheet or parse with csvkit:
```bash
# Filter for in-scope findings only (scope_distance = 0)
csvgrep -c scope_distance -m 0 output.csv

# Get high-value event types
csvgrep -c type -r "VULNERABILITY|FINDING|URL_UNVERIFIED" output.csv
```

### Asset Inventory

**asset_inventory.csv** - Host-centric view

Use `-om asset_inventory` to generate:
- Host column (IP or domain)
- Provider column (AWS, Azure, GCP, etc.)
- IP column
- Open Ports column
- Findings column

Perfect for executive summaries and scope validation.

### Neo4j Graph Visualization

For visual attack surface analysis:

**Setup Neo4j:**
```bash
docker run -p 7687:7687 -p 7474:7474 \
  -v "$(pwd)/neo4j_data:/data" \
  -e NEO4J_AUTH=neo4j/bbotislife \
  neo4j
```

**Run bbot with Neo4j output:**
```bash
bbot -t target.com -p subdomain-enum -om neo4j
```

**Access:** http://localhost:7474 (neo4j/bbotislife)

**Benefits:**
- Visual relationship mapping
- Identify attack paths
- Discover hidden connections
- Team collaboration

---

## High-Value Targets to Identify

When analyzing bbot outputs, prioritize:

### Critical Findings
- **Admin panels** - `/admin`, `/administrator`, `admin.example.com`
- **Dev/staging environments** - `dev.`, `staging.`, `test.`
- **API endpoints** - `/api/`, `/v1/`, `/graphql`
- **Sensitive files** - `.git`, `.env`, `config`, `backup`
- **Cloud resources** - S3 buckets, Azure storage, GCP buckets
- **Certificate mismatches** - Domains in certs not in original scope

### High-Value Assets
- Authentication pages
- File upload functionality
- Database admin interfaces
- Internal documentation
- Employee portals
- VPN/Remote access
- CI/CD pipelines

### Anomalies
- Unexpected technologies (old CMS, legacy apps)
- Unusual port/service combinations
- Orphaned subdomains (no A record but referenced)
- Wildcard DNS misconfigurations

---

## Integration with Other Tools

### Export to Nmap

Convert bbot discoveries to nmap targets:

```bash
# Extract live hosts
cat output.json | jq -r 'select(.type=="DNS_NAME") | .data' | sort -u > targets.txt

# Run targeted nmap scan
nmap -sV -sC -iL targets.txt -oA nmap_scan

# Or just discovered IPs
cat output.json | jq -r 'select(.type=="IP_ADDRESS") | .data' | sort -u > ips.txt
nmap -p- -iL ips.txt -oA full_port_scan
```

### Export to Nuclei

Prepare target lists for nuclei:

```bash
# Extract all HTTP URLs
cat output.json | jq -r 'select(.type=="URL") | .data' | sort -u > urls.txt

# Run nuclei vulnerability scan
nuclei -l urls.txt -t cves/ -t vulnerabilities/ -o nuclei_results.txt
```

### Export to Burp Suite

Load discovered domains/URLs into Burp:

```bash
# Generate simple URL list
cat output.json | jq -r 'select(.type=="URL") | .data' > burp_targets.txt
```

Import `burp_targets.txt` into Burp Target scope.

### Feed into Subdomain Takeover Checks

```bash
# Extract subdomains with CNAME records
cat output.json | jq -r 'select(.type=="DNS_NAME_UNRESOLVED") | .data' > cnames.txt

# Check for takeovers with subzy
subzy run --targets cnames.txt
```

---

## Best Practices

### API Key Configuration

For maximum subdomain discovery, configure API keys in `~/.bbot/config/bbot.yml`:

```yaml
modules:
  shodan:
    api_key: YOUR_SHODAN_API_KEY
  censys:
    api_id: YOUR_CENSYS_ID
    api_secret: YOUR_CENSYS_SECRET
  virustotal:
    api_key: YOUR_VT_API_KEY
  securitytrails:
    api_key: YOUR_ST_API_KEY
  github:
    api_key: YOUR_GITHUB_TOKEN
```

**Impact:** API-enabled modules find significantly more subdomains than public sources alone.

### Scope Management

Always define scope precisely:

**Strict Scope (exact targets only):**
```bash
bbot -t target.com --strict-scope
```
- Only scans exactly target.com
- No subdomain expansion
- Use for very limited scope

**Whitelists (override scope):**
```bash
bbot -t target.com --whitelist 192.0.2.0/24
```
- Allows scanning of whitelisted ranges even if out-of-scope
- Useful for known in-scope IP blocks

**Blacklists (exclude from scanning):**
```bash
bbot -t target.com --blacklist prod.target.com --blacklist "RE:internal"
```
- Prevents scanning of specific hosts
- Supports regex patterns
- Critical for avoiding out-of-scope systems

**Report Distance:**
Control what appears in outputs:
```bash
bbot -t target.com -c scope.report_distance=1
```
- 0 = Only direct targets
- 1 = One hop away (default)
- 2+ = Extended discoveries

### Performance Optimization

**For Large Scopes:**
```bash
# Increase thread count (default: 25)
bbot -t target.com -p subdomain-enum -c threads=50

# Limit scan duration
bbot -t target.com -p kitchen-sink --timeout 3600  # 1 hour max
```

**For Rate Limiting:**
```bash
# Slow down aggressive modules
bbot -t target.com -p subdomain-enum -c http_timeout=10 -c max_http_connections=5
```

### Incremental Scanning

Start light, go deeper:

```bash
# Day 1: Passive only
bbot -t target.com -f safe -rf passive -n day1_passive

# Day 2: Add active subdomain enum
bbot -t target.com -p subdomain-enum -n day2_active

# Day 3: Deep web scanning on interesting targets
bbot -t admin.target.com,api.target.com -p spider -p web-basic -n day3_web

# Day 4: Comprehensive if authorized
bbot -t target.com -p kitchen-sink --allow-deadly -n day4_comprehensive
```

### Data Management

BBOT keeps last 20 scans by default in `~/.bbot/scans/`.

**Organize outputs:**
```bash
# Always use custom output directory
-o ~/pentests/CLIENT/outputs/DATE

# Use descriptive names
-n passive_recon_megacorp_20260110
```

**Archive important scans:**
```bash
# Compress completed scan
tar -czf megacorp_scan_20260110.tar.gz ~/.bbot/scans/scan_name/
```

---

## Common Workflows

### Workflow 1: Initial External Pentest (3 Phases)

**Day 1 - Passive Recon:**
```bash
bbot -t target.com -f safe -rf passive -om json,csv -o outputs/passive -n day1
# Deliverable: Subdomain list, emails, tech stack
```

**Day 2-3 - Active Discovery:**
```bash
bbot -t target.com -p subdomain-enum -m portscan httpx gowitness -om json,csv,neo4j -o outputs/active -n day2
# Deliverable: Live hosts, ports, web apps, screenshots
```

**Day 4-5 - Deep Enumeration:**
```bash
# Targeted scans on interesting finds
bbot -t api.target.com,admin.target.com -p spider -p web-basic -m nuclei --strict-scope -o outputs/web -n web_scan
# Deliverable: Vulnerabilities, parameters, directories
```

### Workflow 2: Rapid Assessment (Single Comprehensive Scan)

**For time-limited engagements:**
```bash
bbot -t target.com -p kitchen-sink --allow-deadly -om json,csv,neo4j,asset_inventory -o outputs/rapid -n rapid_assessment
# Deliverable: Complete attack surface map in one scan
```

### Workflow 3: Continuous Monitoring (Scheduled Recurring)

**For attack surface management:**
```bash
# Weekly subdomain discovery
0 0 * * 0 bbot -t target.com -p subdomain-enum -om json,csv,neo4j -o /scans/weekly_$(date +\%Y\%m\%d) -n weekly_scan

# Compare with previous week to detect new assets
diff <(jq -r 'select(.type=="DNS_NAME") | .data' week1/output.json | sort) \
     <(jq -r 'select(.type=="DNS_NAME") | .data' week2/output.json | sort)
```

---

## Troubleshooting

### Module Not Running

Check module flags:
```bash
# List all available modules
bbot --help-all

# See which modules will run
bbot -t target.com -p subdomain-enum --dry-run
```

### No Results

**Likely causes:**
1. Scope too strict - Try removing `--strict-scope`
2. Blacklists too broad - Review `--blacklist` arguments
3. Target unreachable - Verify DNS resolution
4. Missing API keys - Configure keys for better coverage

### Rate Limiting

Slow down scanning:
```bash
bbot -t target.com -p subdomain-enum -c http_timeout=10 -c max_http_connections=3
```

### Scan Taking Too Long

Limit scope or modules:
```bash
# Reduce module count
bbot -t target.com -f subdomain-enum -ef brute-force

# Set timeout
bbot -t target.com -p subdomain-enum --timeout 1800  # 30 minutes
```

---

## Example Interactions

### Scenario 1: User Asks for Initial Recon Guidance

**User:** "I'm starting a pentest for acmecorp.com. What bbot command should I run first?"

**Response:**
For initial reconnaissance on Day 1, start with passive OSINT to avoid alerting the target:

```bash
bbot -t acmecorp.com \
  -f safe -rf passive \
  -om json,csv \
  -o outputs/recon/passive_$(date +%Y%m%d) \
  -n passive_acmecorp
```

This will:
- Only use safe, passive modules (no direct target contact)
- Gather subdomains from certificate transparency, DNS databases, and APIs
- Output JSON and CSV for easy analysis
- Save results to organized directory with timestamp

**What to look for in outputs:**
1. Discovered subdomains → Create scope list
2. Email addresses → Potential for targeted phishing (if in scope)
3. IP addresses → Prepare for active scanning
4. Cloud resources → Check for misconfigurations

**Next steps:**
Once authorized for active testing, run subdomain-enum preset to validate and expand findings.

### Scenario 2: User Provides bbot Output for Analysis

**User:** [pastes bbot JSON output]

**Response:**
Let me analyze these bbot results for high-value targets...

**Findings:**
1. **Admin Panel Discovered:** `https://admin.acmecorp.com` - Priority target for authentication testing
2. **Dev Environment:** `dev-api.acmecorp.com` - Often has weaker security controls, test thoroughly
3. **Exposed .git Directory:** `https://old.acmecorp.com/.git` - Potential source code disclosure (use git-dumper)
4. **S3 Bucket:** `acmecorp-backups.s3.amazonaws.com` - Check for public read access

**Recommended Actions:**
```bash
# Test S3 bucket permissions
aws s3 ls s3://acmecorp-backups --no-sign-request

# Extract .git repository
git-dumper https://old.acmecorp.com/.git ./source_code

# Run nuclei on admin panel
nuclei -u https://admin.acmecorp.com -t cves/ -t vulnerabilities/

# Deep scan dev API
bbot -t dev-api.acmecorp.com -p spider -m paramminer --strict-scope
```

Document these findings in your Findings.md with MEDIUM-HIGH severity.

### Scenario 3: User Asks About Scope Management

**User:** "I need to scan acmecorp.com but exclude production systems and only scan the 192.0.2.0/24 range."

**Response:**
Use whitelist and blacklist to precisely control scope:

```bash
bbot -t acmecorp.com \
  -p subdomain-enum \
  --whitelist 192.0.2.0/24 \
  --blacklist prod.acmecorp.com \
  --blacklist "RE:production" \
  -om json,csv \
  -o outputs/scoped_scan \
  -n acmecorp_scoped
```

**Explanation:**
- `--whitelist 192.0.2.0/24` - Only this IP range will be scanned, even if other IPs discovered
- `--blacklist prod.acmecorp.com` - Explicitly exclude production subdomain
- `--blacklist "RE:production"` - Exclude any subdomain matching "production" (regex)

**Verify scope before running:**
```bash
# Dry run to see what will be scanned
bbot -t acmecorp.com -p subdomain-enum --whitelist 192.0.2.0/24 --blacklist prod.acmecorp.com --dry-run
```

This prevents accidental scanning of out-of-scope systems.

---

## When to Recommend Other Skills

Based on user needs, recommend:

| User Need | Recommend Skill |
|-----------|-----------------|
| Need nmap/nuclei/other tool commands | `/external-enum` |
| Want to analyze tool output → format finding | `/external-findings` |
| Need guidance on external pentest phases | `/external-pentest-init` |
| Asking about nuclei templates/scanning | `/nuclei-helper` |
| General enumeration beyond bbot | `/external-enum` |

**This skill's focus:** BBOT-specific guidance, command construction, output analysis

---

## References

For deeper content, see:
- `references/presets-guide.md` - Detailed preset documentation and module lists
- `references/workflow-templates.md` - Common engagement patterns and phased approaches
- `references/output-analysis.md` - Advanced output parsing and jq examples

For working examples:
- `examples/passive-recon.md` - Complete passive reconnaissance workflow
- `examples/active-discovery.md` - Active subdomain enumeration and validation
- `examples/comprehensive-scan.md` - Kitchen-sink comprehensive assessment

---

## Response Style

**Command Recommendations:**
- Always include full commands (no placeholders)
- Explain each flag and why it's used
- Provide expected outputs
- Suggest next steps

**Output Analysis:**
- Highlight critical findings first
- Provide jq/grep commands for parsing
- Recommend specific follow-up actions
- Format for easy copy-paste

**Troubleshooting:**
- Identify likely causes
- Provide specific fixes
- Test solutions when possible
- Escalate if needed

Keep responses practical, actionable, and focused on helping the user complete their external pentest efficiently and thoroughly.
