# PAI Knowledge System Configuration
# Copy this file to .env and configure your API keys
# Location: src/config/.env

# ============================================================================
# DEDICATED CONFIGURATION FOR THIS PACK
# ============================================================================
# This pack uses PAI_KNOWLEDGE_* prefixed variables to avoid conflicts with
# other packs that may use the same services. These variables will be
# automatically mapped to standard container environment variables during
# startup (e.g., PAI_KNOWLEDGE_LLM_PROVIDER â†’ LLM_PROVIDER in container).
#
# Benefits:
#   - Clear ownership: Each variable is pack-specific
#   - No conflicts: Different packs can use different settings
#   - Separate billing: Track costs per pack
#   - Independent rate limits: One pack doesn't affect another
#
# For example:
#   - gpt-image-1 pack uses OPENAI_API_KEY, MODEL_NAME, etc.
#   - pai-knowledge-system pack uses PAI_KNOWLEDGE_OPENAI_API_KEY,
#     PAI_KNOWLEDGE_MODEL_NAME, etc.
#
# During installation, the installer will:
#   1. Check if PAI_KNOWLEDGE_* variables exist in ~/.config/pai/.env
#   2. If found, display values and ask to confirm
#   3. If not found, prompt for new values
#   4. Store in both ~/.config/pai/.env and this .env file
# ============================================================================

# ============================================================================
# API Keys (pack-specific)
# ============================================================================

# Primary API Key - Required for most users
# Get your key from: https://platform.openai.com/api-keys
PAI_KNOWLEDGE_OPENAI_API_KEY=sk-your-openai-api-key-here

# Optional: Alternative LLM providers
# Uncomment if you want to use these instead of OpenAI
# ANTHROPIC_API_KEY=your-anthropic-api-key
# GOOGLE_API_KEY=your-google-api-key
# GROQ_API_KEY=your-groq-api-key
# VOYAGE_API_KEY=your-voyage-api-key

# ============================================================================
# LLM Provider Configuration (pack-specific)
# ============================================================================

# LLM Provider: openai, anthropic, gemini, or groq
PAI_KNOWLEDGE_LLM_PROVIDER=openai

# Embeddings Provider: openai (most others require OpenAI for embeddings)
PAI_KNOWLEDGE_EMBEDDER_PROVIDER=openai

# Model name (adjust based on your provider)
# OpenAI: gpt-4o-mini (recommended), gpt-4o, gpt-3.5-turbo
# Anthropic: claude-sonnet-4-20250514
# Gemini: gemini-2.0-flash-exp
# Groq: llama-3.3-70b-versatile
PAI_KNOWLEDGE_MODEL_NAME=gpt-4o-mini

# ============================================================================
# Database Configuration (pack-specific)
# ============================================================================

# Database type: falkordb or neo4j
# This system uses FalkorDB by default
PAI_KNOWLEDGE_DATABASE_TYPE=falkordb

# FalkorDB connection (public network - DO NOT MODIFY)
# These are set automatically by the container orchestration
FALKORDB_HOST=pai-knowledge-falkordb
FALKORDB_PORT=6379

# FalkorDB Password (optional - leave empty for no authentication)
FALKORDB_PASSWORD=

# Optional: Neo4j configuration (if you prefer Neo4j over FalkorDB)
# NEO4J_URI=bolt://localhost:7687
# NEO4J_USER=neo4j
# NEO4J_PASSWORD=demodemo

# ============================================================================
# Performance Configuration (pack-specific)
# ============================================================================

# Concurrency limit for parallel LLM requests
# Adjust based on your API tier:
#   Free tier:   2-5
#   Tier 2:      8
#   Tier 3:      10 (default)
#   Tier 4:      20
PAI_KNOWLEDGE_SEMAPHORE_LIMIT=10

# ============================================================================
# Knowledge Graph Configuration (pack-specific)
# ============================================================================

# Group ID - allows multiple isolated knowledge graphs
# Use 'main' for your primary graph
PAI_KNOWLEDGE_GROUP_ID=main

# ============================================================================
# Telemetry (pack-specific)
# ============================================================================

# Disable Graphiti telemetry
PAI_KNOWLEDGE_GRAPHITI_TELEMETRY_ENABLED=false

# ============================================================================
# Network Architecture Notes
# ============================================================================
#
# This system uses a public bridge network (pai-knowledge-net):
#
# 1. Both FalkorDB and MCP server containers run on the same network
#    - Containers communicate via service names
#    - Network is accessible for inter-container communication
#
# 2. MCP Server container connects to FalkorDB via service name
#    - FALKORDB_HOST is set to: pai-knowledge-falkordb
#    - No manual URI configuration needed
#
# 3. Exposed ports (host access):
#    - 8000: MCP server HTTP endpoint
#    - 3000: FalkorDB web UI
#
# ============================================================================
